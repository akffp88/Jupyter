{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero_One_Classification.py\n",
    "\n",
    "### Tensorflow, pandas 라이브러리 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf #Tensorflow 추가\n",
    "import pandas as pd #pandas추가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습(Training) 데이터(pixel_data, label_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_data = [[0, 1, 0, 1, 1, 1, 1, 1, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0], [1, 1, 0, 1, 1, 0, 1, 1, 0], [0, 1, 1, 0, 1, 1, 0, 1, 1], [0, 1, 0, 1, 1, 1, 1, 1, 1], [1, 1, 0, 1, 0, 1, 1, 1, 1],[0, 1, 0, 0, 1, 0, 0, 1, 0], [0, 1, 0, 1, 1, 0, 1, 1, 0], [0, 0, 1, 0, 1, 1, 0, 1, 0], [0, 0, 1, 0, 0, 1, 1, 1, 1], [0, 0, 1, 0, 1, 1, 0, 1, 0], [0, 1, 0, 0, 1, 0, 0, 0, 1]] #내가 작성한 픽셀 데이터\n",
    "\n",
    "label_data = [[0],[0],[0],[0],[0],[0],[1],[1],[1],[1],[1],[1]] #내가 작성한 픽셀 데이터의 Label 값"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 테스트 데이터(test_pixel, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pixel = [[1, 1, 1, 1, 0, 1, 1, 1, 1],[0, 1, 0, 0, 1, 0, 0, 0, 1]] #학습된 모델 테스트에 사용할 픽셀 데이터\n",
    "\n",
    "test_label = [[0],[1]] #학습된 모델 테스트에 사용할 Label 값"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensorflow 라이브러리를 이용하여 네트워크 만들기\n",
    "#### Input Layer 노드의 수 : 9개\n",
    "#### Hidden Layer 노드의 수 : 1개\n",
    "#### Output Layer 노드의 수 : 1개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://postfiles.pstatic.net/MjAxODA3MjZfMTM0/MDAxNTMyNTgxOTg5OTIx.pQI8g428aZFmosp5HTedc18MLBJBoDMPKBh9ipaiuokg.75k4l98hwfqHYgYgNYWrEmvb0_3d8IYAKFSRXYiMGqMg.JPEG.akffp08/zero_one-1.JPG?type=w966\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src=\"https://postfiles.pstatic.net/MjAxODA3MjZfMTM0/MDAxNTMyNTgxOTg5OTIx.pQI8g428aZFmosp5HTedc18MLBJBoDMPKBh9ipaiuokg.75k4l98hwfqHYgYgNYWrEmvb0_3d8IYAKFSRXYiMGqMg.JPEG.akffp08/zero_one-1.JPG?type=w966\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow로 구성한 네트워크를 실행시키기 위한 Session 유형 변수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "#Tensorflow에서 값을 처리하기 위해 필요한 Session 유형의 변수를 sess로 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=([None,9]),name=\"X\") #9개의 픽셀 데이터에 대한 Tensor\n",
    "#shape=(None, 9) : 입력하는 개수가 많을때는 정확히 알 수 없음(None), 한 번에 입력할 때 들어가는 데이터의 특징의 수 : 픽셀 9칸 -> 9\n",
    "#Input Layer 노드의 수 = 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = tf.placeholder(tf.int32, shape=([None,1]),name=\"Y\") #X에 입력한 픽셀의 실제 Label 값에 대한 Tensor\n",
    "#shape=(None, 1) : Output Layer의 노드의 수 = 1\n",
    "Y_one_hot = tf.one_hot(Y, 2, name=\"Y_one_hot\")  #Output Layer 노드의 수가 1개로 0인지 1인지 구별하기 위해 사용하는 방법이 One-hot encoding\n",
    "Y_one_hot = tf.reshape(Y_one_hot, [-1, 2]) #[-1, 2]의 형태로 변환 -> -1 : 몇 개의 데이터를 사용할 지 모른다는 의미, 2 : 0, 1로 구별하겠다는 의미 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hidden Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#첫번째 Hidden Layer 설정\n",
    "W1 = tf.Variable(tf.random_normal([9,2]),name='W1') #Input Layer의 각 노드에 대한 가중치(Weight)\n",
    "#W1 : 첫번째 Hidden Layer의 노드 1개, 가중치는 2 x 9 = 18개\n",
    "        \n",
    "b1 = tf.Variable(tf.zeros([2]),name='b1') #Input Layer의 각 노드에 대한 편향(bias)\n",
    "#b1 : 첫번째 Hidden Layer의 각 노드의 bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = tf.matmul(X, W1) + b1 #입력한 데이터를 기반으로 가중치와 편향을 반영한 그래프\n",
    "\n",
    "hypothesis = tf.nn.softmax(logits) #Softmax 함수를 hypothesis로 선정\n",
    "#입력데이터와 출력 데이터의 관계(Relationship) 또는 패턴(Pattern)을 나타내기 위한 함수 : hypothesis\n",
    "            \n",
    "cost_i = tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits,labels=Y_one_hot) #Input Layer 노드 9개 각각에 대한 Cost계산\n",
    "#Logits를 통해 그려진 그래프와, hypothesis를 통해 판별한 결과의 오차를 계산\n",
    "            \n",
    "cost = tf.reduce_mean(cost_i) #전체 9개 Input Node의 오차의 평균\n",
    "    \n",
    "optimization = tf.train.GradientDescentOptimizer(learning_rate=0.05).minimize(cost) #경사하강법(Gradient-Descent)를 이용하여 학습\n",
    "#학습률(Learning_rate) : 0.05 -> 학습을 하는 과정에서 경사를 하강하는 폭의 정도 -> 작을 수록 폭이 좁음, 넓을 수록 폭이 넓음\n",
    "\n",
    "prediction = tf.argmax(hypothesis, 1) #우리가 선정한 hypothesis 함수를 기반으로 Classification한 결과\n",
    "correct_prediction = tf.equal(prediction, tf.argmax(Y_one_hot, 1)) #Prediction의 결과가 실제 Label 값과 맞는지 여부\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) #Prediction의 정확성을 저장하는 변수\n",
    "            \n",
    "sess.run(tf.global_variables_initializer()) #Tensorflow의 변수 초기화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 구성한 네트워크를 기반으로 1001번 반복하며 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:     0\tLoss: 1.597\tAcc: 41.67%\n",
      "Step:  1000\tLoss: 0.354\tAcc: 75.00%\n"
     ]
    }
   ],
   "source": [
    "for step in range(1001): #1001번 반복\n",
    "    _ = sess.run(optimization, feed_dict={X:pixel_data,Y:label_data}) \n",
    "    #입력은 pixel_data, Prediction 결과 비교를 위한 Y는 lable_data로 사용하여 학습\n",
    "    \n",
    "    if step % 1000 == 0:\n",
    "        loss, acc = sess.run([cost, accuracy], feed_dict={X: pixel_data, Y: label_data})\n",
    "        print(\"Step: {:5}\\tLoss: {:.3f}\\tAcc: {:.2%}\".format(step, loss, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습한 결과 테스트하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Prediction = 0.5\n",
      "   Predict_Value Origin_Value  Correct\n",
      "0              0          [0]     True\n",
      "1              0          [1]    False\n"
     ]
    }
   ],
   "source": [
    "test_acc,test_predict,test_correct = sess.run([accuracy,prediction,correct_prediction], feed_dict={X: test_pixel, Y: test_label})\n",
    "\n",
    "print(\"Test Prediction =\", test_acc)        \n",
    "sub = pd.DataFrame() #Test 결과를 저장하기 위한 Data구조 생성\n",
    "sub['Predict_Value'] = test_predict #모델이 예측한 값 \n",
    "sub['Origin_Value'] = test_label #실제 Label 값\n",
    "sub['Correct'] = test_correct #모델이 예측한 값과 실제 Label 값이 맞는지 여부\n",
    "\n",
    "print(sub)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
